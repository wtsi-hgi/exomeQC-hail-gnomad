{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pip-installed Hail requires additional configuration options in Spark referring\n",
      "  to the path to the Hail Python module directory HAIL_DIR,\n",
      "  e.g. /path/to/python/site-packages/hail:\n",
      "    spark.jars=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.driver.extraClassPath=HAIL_DIR/hail-all-spark.jar\n",
      "    spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 2.4.5\n",
      "SparkUI available at http://spark-master:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.41-b8144dba46e6\n",
      "LOGGING: writing to /home/ubuntu/data/tmp/scripts/sanger_gnomad_hail_qc/notebooks/hail-20201111-1403-0.2.41-b8144dba46e6.log\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import hail as hl\n",
    "import pyspark\n",
    "import bokeh\n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle \n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Any, Counter, List, Optional, Tuple, Union,Dict,Set, Iterable\n",
    "from hail.plot import show, output_notebook\n",
    "from bokeh.palettes import d3  # pylint: disable=no-name-in-module\n",
    "from bokeh.models import Plot, Row, Span, NumeralTickFormatter, LabelSet\n",
    "from gnomad.utils.plotting import *\n",
    "from typing import Set, Tuple\n",
    "\n",
    "tmp_dir = \"hdfs://spark-master:9820/\"\n",
    "temp_dir = \"file:///home/ubuntu/data/tmp\"\n",
    "plot_dir = \"/home/ubuntu/data/tmp\"\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "hadoop_config = sc._jsc.hadoopConfiguration()\n",
    "hadoop_config.set(\"fs.s3a.access.key\", \"8YY584J59H7Q6AVKHSU8\")\n",
    "hadoop_config.set(\"fs.s3a.secret.key\", \"P8vePa7JUvxKXX2me9ti1cGujgYWMoimAwx4mMlM\")\n",
    "hadoop_config.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_config.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hl.init(sc=sc, tmp_dir=tmp_dir, default_reference='GRCh38')\n",
    "output_notebook()\n",
    "logging.basicConfig(format=\"%(levelname)s (%(name)s %(lineno)s): %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant and Sample QC with hail - to try and recreate with opencga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read chr19 from the exome WES cohort with 93674 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt=hl.read_matrix_table(f\"{temp_dir}/ddd-elgh-ukbb/chr19.mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        AC: array<int32>, \n",
      "        AF: array<float64>, \n",
      "        AN: int32, \n",
      "        AS_BaseQRankSum: array<float64>, \n",
      "        AS_FS: array<float64>, \n",
      "        AS_InbreedingCoeff: array<float64>, \n",
      "        AS_MQ: array<float64>, \n",
      "        AS_MQRankSum: array<float64>, \n",
      "        AS_QD: array<float64>, \n",
      "        AS_ReadPosRankSum: array<float64>, \n",
      "        AS_SOR: array<float64>, \n",
      "        BaseQRankSum: float64, \n",
      "        DB: bool, \n",
      "        DP: int32, \n",
      "        DS: bool, \n",
      "        END: int32, \n",
      "        ExcessHet: float64, \n",
      "        FS: float64, \n",
      "        InbreedingCoeff: float64, \n",
      "        MLEAC: array<int32>, \n",
      "        MLEAF: array<float64>, \n",
      "        MQ: float64, \n",
      "        MQRankSum: float64, \n",
      "        QD: float64, \n",
      "        RAW_MQandDP: array<int32>, \n",
      "        ReadPosRankSum: float64, \n",
      "        SOR: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'AD': array<int32>\n",
      "    'DP': int32\n",
      "    'GQ': int32\n",
      "    'GT': call\n",
      "    'MIN_DP': int32\n",
      "    'PGT': call\n",
      "    'PID': str\n",
      "    'PL': array<int32>\n",
      "    'PS': int32\n",
      "    'RGQ': int32\n",
      "    'SB': array<int32>\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663562, 93674)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant QC with hail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_vqc=hl.variant_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        AC: array<int32>, \n",
      "        AF: array<float64>, \n",
      "        AN: int32, \n",
      "        AS_BaseQRankSum: array<float64>, \n",
      "        AS_FS: array<float64>, \n",
      "        AS_InbreedingCoeff: array<float64>, \n",
      "        AS_MQ: array<float64>, \n",
      "        AS_MQRankSum: array<float64>, \n",
      "        AS_QD: array<float64>, \n",
      "        AS_ReadPosRankSum: array<float64>, \n",
      "        AS_SOR: array<float64>, \n",
      "        BaseQRankSum: float64, \n",
      "        DB: bool, \n",
      "        DP: int32, \n",
      "        DS: bool, \n",
      "        END: int32, \n",
      "        ExcessHet: float64, \n",
      "        FS: float64, \n",
      "        InbreedingCoeff: float64, \n",
      "        MLEAC: array<int32>, \n",
      "        MLEAF: array<float64>, \n",
      "        MQ: float64, \n",
      "        MQRankSum: float64, \n",
      "        QD: float64, \n",
      "        RAW_MQandDP: array<int32>, \n",
      "        ReadPosRankSum: float64, \n",
      "        SOR: float64\n",
      "    }\n",
      "    'variant_qc': struct {\n",
      "        dp_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        gq_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        AC: array<int32>, \n",
      "        AF: array<float64>, \n",
      "        AN: int32, \n",
      "        homozygote_count: array<int32>, \n",
      "        call_rate: float64, \n",
      "        n_called: int64, \n",
      "        n_not_called: int64, \n",
      "        n_filtered: int64, \n",
      "        n_het: int64, \n",
      "        n_non_ref: int64, \n",
      "        het_freq_hwe: float64, \n",
      "        p_value_hwe: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'AD': array<int32>\n",
      "    'DP': int32\n",
      "    'GQ': int32\n",
      "    'GT': call\n",
      "    'MIN_DP': int32\n",
      "    'PGT': call\n",
      "    'PID': str\n",
      "    'PL': array<int32>\n",
      "    'PS': int32\n",
      "    'RGQ': int32\n",
      "    'SB': array<int32>\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mt_vqc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt=mt.annotate_rows(fail_hard_filters= (mt.info.QD < 2) | (mt.info.FS > 60) | (mt.info.MQ < 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many variants fail these filters and what percent of total variants is it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_hard_filters_count=mt.aggregate_rows(hl.agg.count_where(mt.fail_hard_filters==True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81127"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(fail_hard_filters_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.876704324816268"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "81127/1663562*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out these variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_filtered=mt.filter_rows(mt.fail_hard_filters==True,keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1582219, 93674)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run variant_qc for new subset of variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_filtered_vqc=hl.variant_qc(mt_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample QC with hail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_sqc=hl.sample_qc(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic calculations of sample qc metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "    'sample_qc': struct {\n",
      "        dp_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        gq_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        call_rate: float64, \n",
      "        n_called: int64, \n",
      "        n_not_called: int64, \n",
      "        n_filtered: int64, \n",
      "        n_hom_ref: int64, \n",
      "        n_het: int64, \n",
      "        n_hom_var: int64, \n",
      "        n_non_ref: int64, \n",
      "        n_singleton: int64, \n",
      "        n_snp: int64, \n",
      "        n_insertion: int64, \n",
      "        n_deletion: int64, \n",
      "        n_transition: int64, \n",
      "        n_transversion: int64, \n",
      "        n_star: int64, \n",
      "        r_ti_tv: float64, \n",
      "        r_het_hom_var: float64, \n",
      "        r_insertion_deletion: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        AC: array<int32>, \n",
      "        AF: array<float64>, \n",
      "        AN: int32, \n",
      "        AS_BaseQRankSum: array<float64>, \n",
      "        AS_FS: array<float64>, \n",
      "        AS_InbreedingCoeff: array<float64>, \n",
      "        AS_MQ: array<float64>, \n",
      "        AS_MQRankSum: array<float64>, \n",
      "        AS_QD: array<float64>, \n",
      "        AS_ReadPosRankSum: array<float64>, \n",
      "        AS_SOR: array<float64>, \n",
      "        BaseQRankSum: float64, \n",
      "        DB: bool, \n",
      "        DP: int32, \n",
      "        DS: bool, \n",
      "        END: int32, \n",
      "        ExcessHet: float64, \n",
      "        FS: float64, \n",
      "        InbreedingCoeff: float64, \n",
      "        MLEAC: array<int32>, \n",
      "        MLEAF: array<float64>, \n",
      "        MQ: float64, \n",
      "        MQRankSum: float64, \n",
      "        QD: float64, \n",
      "        RAW_MQandDP: array<int32>, \n",
      "        ReadPosRankSum: float64, \n",
      "        SOR: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'AD': array<int32>\n",
      "    'DP': int32\n",
      "    'GQ': int32\n",
      "    'GT': call\n",
      "    'MIN_DP': int32\n",
      "    'PGT': call\n",
      "    'PID': str\n",
      "    'PL': array<int32>\n",
      "    'PS': int32\n",
      "    'RGQ': int32\n",
      "    'SB': array<int32>\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mt_sqc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate samples with their population assignments. \n",
    "### These assignments are the result of a previous investigation within the ongoing gnomad_qc project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-11 14:03:46 Hail: INFO: Reading table with no type imputation\n",
      "  Loading column 's' as type 'str' (type not specified)\n",
      "  Loading column 'known_pop' as type 'str' (type not specified)\n",
      "  Loading column 'pca_scores' as type 'str' (type not specified)\n",
      "  Loading column 'pop' as type 'str' (type not specified)\n",
      "  Loading column 'prob_African' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Any other Asian background' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Any other Black background' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Any other mixed background' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Any other white background' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Asian or Asian British' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Bangladeshi' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Black or Black British' as type 'str' (type not specified)\n",
      "  Loading column 'prob_British' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Caribbean' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Chinese' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Do not know' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Indian' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Irish' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Mixed' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Other ethnic group' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Pakistani' as type 'str' (type not specified)\n",
      "  Loading column 'prob_Prefer not to answer' as type 'str' (type not specified)\n",
      "  Loading column 'prob_White' as type 'str' (type not specified)\n",
      "  Loading column 'prob_White and Asian' as type 'str' (type not specified)\n",
      "  Loading column 'prob_White and Black African' as type 'str' (type not specified)\n",
      "  Loading column 'prob_White and Black Caribbean' as type 'str' (type not specified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "populations=hl.import_table(f\"{temp_dir}/ddd-elgh-ukbb/pop_assignments.tsv\").key_by('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(f\"{temp_dir}/ddd-elgh-ukbb/pop_assignments.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s', 'known_pop', 'pca_scores', 'pop', 'prob_African',\n",
       "       'prob_Any other Asian background', 'prob_Any other Black background',\n",
       "       'prob_Any other mixed background', 'prob_Any other white background',\n",
       "       'prob_Asian or Asian British', 'prob_Bangladeshi',\n",
       "       'prob_Black or Black British', 'prob_British', 'prob_Caribbean',\n",
       "       'prob_Chinese', 'prob_Do not know', 'prob_Indian', 'prob_Irish',\n",
       "       'prob_Mixed', 'prob_Other ethnic group', 'prob_Pakistani',\n",
       "       'prob_Prefer not to answer', 'prob_White', 'prob_White and Asian',\n",
       "       'prob_White and Black African', 'prob_White and Black Caribbean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oth                           52358\n",
       "British                       40806\n",
       "Caribbean                       243\n",
       "Indian                          176\n",
       "Chinese                          75\n",
       "White and Black Caribbean         7\n",
       "African                           7\n",
       "Any other white background        1\n",
       "Other ethnic group                1\n",
       "Name: pop, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pop\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     93674\n",
       "unique        9\n",
       "top         oth\n",
       "freq      52358\n",
       "Name: pop, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pop\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Annotate samples with their population information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_sqc=mt_sqc.annotate_cols(pop=populations[mt_sqc.s].pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    's': str \n",
      "    'sample_qc': struct {\n",
      "        dp_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        gq_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        call_rate: float64, \n",
      "        n_called: int64, \n",
      "        n_not_called: int64, \n",
      "        n_filtered: int64, \n",
      "        n_hom_ref: int64, \n",
      "        n_het: int64, \n",
      "        n_hom_var: int64, \n",
      "        n_non_ref: int64, \n",
      "        n_singleton: int64, \n",
      "        n_snp: int64, \n",
      "        n_insertion: int64, \n",
      "        n_deletion: int64, \n",
      "        n_transition: int64, \n",
      "        n_transversion: int64, \n",
      "        n_star: int64, \n",
      "        r_ti_tv: float64, \n",
      "        r_het_hom_var: float64, \n",
      "        r_insertion_deletion: float64\n",
      "    } \n",
      "    'pop': str \n",
      "----------------------------------------\n",
      "Key: ['s']\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-11 14:04:03 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n"
     ]
    }
   ],
   "source": [
    "mt_sqc.cols().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hail table with only the columns from the matrixtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht=mt_sqc.cols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate median scores per population and mark as failed the samples that are outside 4 MAD from median for a list of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_and_mad_expr(\n",
    "    metric_expr: hl.expr.ArrayNumericExpression, k: float = 1.4826\n",
    ") -> hl.expr.StructExpression:\n",
    "    \"\"\"\n",
    "    Computes the median and median absolute deviation (MAD) for the given expression.\n",
    "    Note that the default value of k assumes normally distributed data.\n",
    "\n",
    "    :param metric_expr: Expression to compute median and MAD for\n",
    "    :param k: The scaling factor for MAD calculation. Default assumes normally distributed data.\n",
    "    :return: Struct with median and MAD\n",
    "    \"\"\"\n",
    "    return hl.bind(\n",
    "        lambda x: hl.struct(median=x[1], mad=k *\n",
    "                            hl.median(hl.abs(x[0] - x[1]))),\n",
    "        hl.bind(lambda x: hl.tuple([x, hl.median(x)]),\n",
    "                hl.agg.collect(metric_expr)),\n",
    "    )\n",
    "\n",
    "def compute_stratified_metrics_filter(\n",
    "    ht: hl.Table,\n",
    "    qc_metrics: Dict[str, hl.expr.NumericExpression],\n",
    "    strata: Optional[Dict[str, hl.expr.Expression]] = None,\n",
    "    lower_threshold: float = 4.0,\n",
    "    upper_threshold: float = 4.0,\n",
    "    metric_threshold: Optional[Dict[str, Tuple[float, float]]] = None,\n",
    "    filter_name: str = \"qc_metrics_filters\",\n",
    ") -> hl.Table:\n",
    "    \"\"\"\n",
    "    Compute median, MAD, and upper and lower thresholds for each metric used in outlier filtering\n",
    "\n",
    "    :param ht: HT containing relevant sample QC metric annotations\n",
    "    :param qc_metrics: list of metrics (name and expr) for which to compute the critical values for filtering outliers\n",
    "    :param strata: List of annotations used for stratification. These metrics should be discrete types!\n",
    "    :param lower_threshold: Lower MAD threshold\n",
    "    :param upper_threshold: Upper MAD threshold\n",
    "    :param metric_threshold: Can be used to specify different (lower, upper) thresholds for one or more metrics\n",
    "    :param filter_name: Name of resulting filters annotation\n",
    "    :return: Table grouped by strata, with upper and lower threshold values computed for each sample QC metric\n",
    "    \"\"\"\n",
    "\n",
    "    _metric_threshold = {\n",
    "        metric: (lower_threshold, upper_threshold) for metric in qc_metrics\n",
    "    }\n",
    "    if metric_threshold is not None:\n",
    "        _metric_threshold.update(metric_threshold)\n",
    "\n",
    "    def make_filters_expr(\n",
    "        ht: hl.Table, qc_metrics: Iterable[str]\n",
    "    ) -> hl.expr.SetExpression:\n",
    "        return hl.set(\n",
    "            hl.filter(\n",
    "                lambda x: hl.is_defined(x),\n",
    "                [hl.or_missing(ht[f\"fail_{metric}\"], metric) for metric in qc_metrics],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if strata is None:\n",
    "        strata = {}\n",
    "\n",
    "    ht = ht.select(**qc_metrics, **strata).key_by(\"s\").persist()\n",
    "\n",
    "    agg_expr = hl.struct(\n",
    "        **{\n",
    "            metric: hl.bind(\n",
    "                lambda x: x.annotate(\n",
    "                    lower=x.median - _metric_threshold[metric][0] * x.mad,\n",
    "                    upper=x.median + _metric_threshold[metric][1] * x.mad,\n",
    "                ),\n",
    "                get_median_and_mad_expr(ht[metric]),\n",
    "            )\n",
    "            for metric in qc_metrics\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if strata:\n",
    "        ht = ht.annotate_globals(\n",
    "            qc_metrics_stats=ht.aggregate(\n",
    "                hl.agg.group_by(hl.tuple([ht[x] for x in strata]), agg_expr),\n",
    "                _localize=False,\n",
    "            )\n",
    "        )\n",
    "        metrics_stats_expr = ht.qc_metrics_stats[hl.tuple([ht[x] for x in strata])]\n",
    "    else:\n",
    "        ht = ht.annotate_globals(\n",
    "            qc_metrics_stats=ht.aggregate(agg_expr, _localize=False)\n",
    "        )\n",
    "        metrics_stats_expr = ht.qc_metrics_stats\n",
    "\n",
    "    fail_exprs = {\n",
    "        f\"fail_{metric}\": (ht[metric] <= metrics_stats_expr[metric].lower)\n",
    "        | (ht[metric] >= metrics_stats_expr[metric].upper)\n",
    "        for metric in qc_metrics\n",
    "    }\n",
    "    ht = ht.transmute(**fail_exprs)\n",
    "    stratified_filters = make_filters_expr(ht, qc_metrics)\n",
    "    return ht.annotate(**{filter_name: stratified_filters})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata = {}\n",
    "qc_metrics = {\n",
    "        'sample_qc.n_snp': ht.sample_qc.n_snp,\n",
    "        'sample_qc.r_ti_tv': ht.sample_qc.r_ti_tv,\n",
    "        'sample_qc.r_insertion_deletion': ht.sample_qc.r_insertion_deletion,\n",
    "        'sampleqc.n_insertion': ht.sample_qc.n_insertion,\n",
    "        'sampleqc.n_deletion': ht.sample_qc.n_deletion,\n",
    "        'sample_qc.r_het_hom_var': ht.sample_qc.r_het_hom_var\n",
    "    }\n",
    "strata['pop'] = ht.pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-11 14:34:14 Hail: INFO: Coerced sorted dataset\n"
     ]
    }
   ],
   "source": [
    "pop_filter_ht = compute_stratified_metrics_filter(\n",
    "        ht, qc_metrics, strata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-11 14:35:26 Hail: INFO: wrote table with 93674 rows in 16 partitions to hdfs://spark-master:9820//chr19_pop.ht\n"
     ]
    }
   ],
   "source": [
    "pop_filter_ht.write(f\"{tmp_dir}/chr19_pop.ht\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_filter_ht=hl.read_table(f\"{temp_dir}/ddd-elgh-ukbb/chr19_pop.ht\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Type:\n",
      "        struct {\n",
      "        qc_metrics_stats: dict<tuple (\n",
      "            str\n",
      "        ), struct {\n",
      "            `sample_qc.n_snp`: struct {\n",
      "                median: int64, \n",
      "                mad: float64, \n",
      "                lower: float64, \n",
      "                upper: float64\n",
      "            }, \n",
      "            `sample_qc.r_ti_tv`: struct {\n",
      "                median: float64, \n",
      "                mad: float64, \n",
      "                lower: float64, \n",
      "                upper: float64\n",
      "            }, \n",
      "            `sample_qc.r_insertion_deletion`: struct {\n",
      "                median: float64, \n",
      "                mad: float64, \n",
      "                lower: float64, \n",
      "                upper: float64\n",
      "            }, \n",
      "            `sampleqc.n_insertion`: struct {\n",
      "                median: int64, \n",
      "                mad: float64, \n",
      "                lower: float64, \n",
      "                upper: float64\n",
      "            }, \n",
      "            `sampleqc.n_deletion`: struct {\n",
      "                median: int64, \n",
      "                mad: float64, \n",
      "                lower: float64, \n",
      "                upper: float64\n",
      "            }, \n",
      "            `sample_qc.r_het_hom_var`: struct {\n",
      "                median: float64, \n",
      "                mad: float64, \n",
      "                lower: float64, \n",
      "                upper: float64\n",
      "            }\n",
      "        }>\n",
      "    }\n",
      "--------------------------------------------------------\n",
      "Source:\n",
      "    <hail.table.Table object at 0x7fb605a59278>\n",
      "Index:\n",
      "    []\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pop_filter_ht.globals.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('African',),\n",
       " ('Any other white background',),\n",
       " ('British',),\n",
       " ('Caribbean',),\n",
       " ('Chinese',),\n",
       " ('Indian',),\n",
       " ('Other ethnic group',),\n",
       " ('White and Black Caribbean',),\n",
       " ('oth',)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(pop_filter_ht.globals['qc_metrics_stats'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Struct(sample_qc.n_snp=Struct(median=10530, mad=397.3368, lower=8940.6528, upper=12119.3472), sample_qc.r_ti_tv=Struct(median=2.3009739239710965, mad=0.03810543268110271, lower=2.148552193246686, upper=2.453395654695507), sample_qc.r_insertion_deletion=Struct(median=0.8488210818307905, mad=0.021231487716861272, lower=0.7638951309633455, upper=0.9337470326982356), sampleqc.n_insertion=Struct(median=582, mad=50.4084, lower=380.3664, upper=783.6336), sampleqc.n_deletion=Struct(median=713, mad=103.782, lower=297.872, upper=1128.128), sample_qc.r_het_hom_var=Struct(median=1.7222997488138432, mad=0.01941424357466751, lower=1.644642774515173, upper=1.7999567231125133))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(pop_filter_ht.globals['qc_metrics_stats'][('African',)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Struct(median=10530, mad=397.3368, lower=8940.6528, upper=12119.3472)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(pop_filter_ht.globals['qc_metrics_stats'][('African',)]['sample_qc.n_snp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead style=\"font-weight: bold;\"><tr><td>s</td><td>fail_sample_qc.n_snp</td><td>fail_sample_qc.r_ti_tv</td><td>fail_sample_qc.r_insertion_deletion</td><td>fail_sampleqc.n_insertion</td><td>fail_sampleqc.n_deletion</td><td>fail_sample_qc.r_het_hom_var</td><td>qc_metrics_filters</td></tr>\n",
       "<tr><td>str</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>set&lt;str&gt;</td></tr>\n",
       "</thead><tbody><tr><td>&quot;EGAN00001006259&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>true</td><td>{&quot;sample_qc.r_het_hom_var&quot;}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006260&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>{}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006261&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>true</td><td>{&quot;sample_qc.r_het_hom_var&quot;}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006263&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>true</td><td>{&quot;sample_qc.r_het_hom_var&quot;}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006264&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>true</td><td>{&quot;sample_qc.r_het_hom_var&quot;}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006265&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>{}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006266&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>{}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006267&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>{}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006268&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>{}</td></tr>\n",
       "<tr><td>&quot;EGAN00001006269&quot;</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>false</td><td>{}</td></tr>\n",
       "</tbody></table><p style=\"background: #fdd; padding: 0.4em;\">showing top 10 rows</p>\n"
      ],
      "text/plain": [
       "+-------------------+----------------------+------------------------+-------------------------------------+---------------------------+\n",
       "| s                 | fail_sample_qc.n_snp | fail_sample_qc.r_ti_tv | fail_sample_qc.r_insertion_deletion | fail_sampleqc.n_insertion |\n",
       "+-------------------+----------------------+------------------------+-------------------------------------+---------------------------+\n",
       "| str               |                 bool |                   bool |                                bool |                      bool |\n",
       "+-------------------+----------------------+------------------------+-------------------------------------+---------------------------+\n",
       "| \"EGAN00001006259\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006260\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006261\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006263\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006264\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006265\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006266\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006267\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006268\" |                false |                  false |                               false |                     false |\n",
       "| \"EGAN00001006269\" |                false |                  false |                               false |                     false |\n",
       "+-------------------+----------------------+------------------------+-------------------------------------+---------------------------+\n",
       "\n",
       "+--------------------------+------------------------------+-----------------------------+\n",
       "| fail_sampleqc.n_deletion | fail_sample_qc.r_het_hom_var | qc_metrics_filters          |\n",
       "+--------------------------+------------------------------+-----------------------------+\n",
       "|                     bool |                         bool | set<str>                    |\n",
       "+--------------------------+------------------------------+-----------------------------+\n",
       "|                    false |                         true | {\"sample_qc.r_het_hom_var\"} |\n",
       "|                    false |                        false | {}                          |\n",
       "|                    false |                         true | {\"sample_qc.r_het_hom_var\"} |\n",
       "|                    false |                         true | {\"sample_qc.r_het_hom_var\"} |\n",
       "|                    false |                         true | {\"sample_qc.r_het_hom_var\"} |\n",
       "|                    false |                        false | {}                          |\n",
       "|                    false |                        false | {}                          |\n",
       "|                    false |                        false | {}                          |\n",
       "|                    false |                        false | {}                          |\n",
       "|                    false |                        false | {}                          |\n",
       "+--------------------------+------------------------------+-----------------------------+\n",
       "showing top 10 rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pop_filter_ht.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many samples are outside the 4 MAD from median and failed this QC?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    " failed_samples_count=pop_filter_ht.aggregate(hl.agg.count_where(hl.len(pop_filter_ht.qc_metrics_filters) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1349"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(failed_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Find and remove these failed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_samples=pop_filter_ht.filter((hl.len(pop_filter_ht.qc_metrics_filters) != 0), keep=True)\n",
    "passed_samples=pop_filter_ht.filter((hl.len(pop_filter_ht.qc_metrics_filters) == 0), keep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1349"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_samples.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92325"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passed_samples.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_samples=passed_samples.annotate(PASS=\"PASS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter original matrixtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt=mt.annotate_cols(passed_population_filters=passed_samples[mt.s].PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt=mt.filter_cols(mt.passed_population_filters ==\"PASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663562, 92325)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate new sample QC for new set of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_sqc_new=hl.sample_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    None\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    's': str\n",
      "    'passed_population_filters': str\n",
      "    'sample_qc': struct {\n",
      "        dp_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        gq_stats: struct {\n",
      "            mean: float64, \n",
      "            stdev: float64, \n",
      "            min: float64, \n",
      "            max: float64\n",
      "        }, \n",
      "        call_rate: float64, \n",
      "        n_called: int64, \n",
      "        n_not_called: int64, \n",
      "        n_filtered: int64, \n",
      "        n_hom_ref: int64, \n",
      "        n_het: int64, \n",
      "        n_hom_var: int64, \n",
      "        n_non_ref: int64, \n",
      "        n_singleton: int64, \n",
      "        n_snp: int64, \n",
      "        n_insertion: int64, \n",
      "        n_deletion: int64, \n",
      "        n_transition: int64, \n",
      "        n_transversion: int64, \n",
      "        n_star: int64, \n",
      "        r_ti_tv: float64, \n",
      "        r_het_hom_var: float64, \n",
      "        r_insertion_deletion: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh38>\n",
      "    'alleles': array<str>\n",
      "    'rsid': str\n",
      "    'qual': float64\n",
      "    'filters': set<str>\n",
      "    'info': struct {\n",
      "        AC: array<int32>, \n",
      "        AF: array<float64>, \n",
      "        AN: int32, \n",
      "        AS_BaseQRankSum: array<float64>, \n",
      "        AS_FS: array<float64>, \n",
      "        AS_InbreedingCoeff: array<float64>, \n",
      "        AS_MQ: array<float64>, \n",
      "        AS_MQRankSum: array<float64>, \n",
      "        AS_QD: array<float64>, \n",
      "        AS_ReadPosRankSum: array<float64>, \n",
      "        AS_SOR: array<float64>, \n",
      "        BaseQRankSum: float64, \n",
      "        DB: bool, \n",
      "        DP: int32, \n",
      "        DS: bool, \n",
      "        END: int32, \n",
      "        ExcessHet: float64, \n",
      "        FS: float64, \n",
      "        InbreedingCoeff: float64, \n",
      "        MLEAC: array<int32>, \n",
      "        MLEAF: array<float64>, \n",
      "        MQ: float64, \n",
      "        MQRankSum: float64, \n",
      "        QD: float64, \n",
      "        RAW_MQandDP: array<int32>, \n",
      "        ReadPosRankSum: float64, \n",
      "        SOR: float64\n",
      "    }\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'AD': array<int32>\n",
      "    'DP': int32\n",
      "    'GQ': int32\n",
      "    'GT': call\n",
      "    'MIN_DP': int32\n",
      "    'PGT': call\n",
      "    'PID': str\n",
      "    'PL': array<int32>\n",
      "    'PS': int32\n",
      "    'RGQ': int32\n",
      "    'SB': array<int32>\n",
      "----------------------------------------\n",
      "Column key: ['s']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mt_sqc_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
